\chapter{Conclusion}

% This chapter is likely to be very short and it may well refer back to the Introduction. It might properly explain how you would have planned the project if starting again with the benefit of hindsight.

%  ~500 words

\section{Success criteria}
The project has achieved and exceeded all of its success criteria and requirements (Section~\ref{section:requirements-analysis} and Project Proposal, Appendix~\ref{chapter:project-proposal}), representing the UKB dataset as a population graph, implementing the two GNN frameworks, and evaluating their results. It has made a lot of progress on its proposed extensions, measuring the significance and robustness of the GNN models and increasing the flexibility of the preprocessing pipeline to more preprocessing options.

\section{The main contribution}
The main success and contribution of this project was its step towards a preprocessing pipeline that could leverage several brain imaging and non-imaging modalities at once in a unified and consistent manner. This is important in neuroimaging research regardless of the downstream task or analysis method, as there is a widespread community effort to combat the neuroimaging reproducibility crisis~\cite{gorgolewski2016practical} caused by, among other factors, the lack of transparency in preprocessing methods and software errors due to bad software engineering practices~\cite{poldrack2017scanning}.
% \footnote{\url{http://reproducibility.stanford.edu/about-us/}}
% Even for the same dataset, the preprocessing workflow alone could significantly affect the results~\cite{salehi2020there}, and the workflows (particularly for functional data) may vary significantly between different research teams~\cite{botvinik2019variability}. 

While the efforts to improve reproducibility of neuroimaging research are currently targeted at consistent processing of functional and structural MRI with libraries such as \textit{fMRIPrep}~\cite{esteban2019fmriprep} and \textit{Pypes}~\cite{savio2017pypes}, this project, to the best of my knowledge, is one of the first to additionally incorporate non-imaging data modalities. While it was designed to prepare the data specifically for population graphs, due to its modular structure it has sufficient flexibility to be easily extended to more preprocessing options and modalities, and adapted to work independently of the downstream analysis method.

\section{The main lessons}
This interdisciplinary project has been exploring two things – the brain age estimation problem, and graph neural networks as a way of solving it. Both of the machine learning and neuroimaging fields are currently at the height of their ongoing research, with some of the literature this project relied on being only a few months old~\cite{kaufmann2019, niu2019improved, pervaiz2020optimising}. The continuous collaboration with experts from both disciplines was an enriching experience; more importantly, however, this guidance was crucial to ensure that my work is not only a technically challenging, but also a clinically relevant contribution to the neuroscience community.

At the same time, this project taught me first-hand an important lesson in approaching predictive analysis problems in real-world settings. While the goal of this project was to learn more about the advanced, cutting-edge methods in computational neuroscience, and to get hands-on experience with the tools for implementing them, the development of models \textit{in practice} should consider the simplest approaches first and only then apply the more sophisticated techniques. This was demonstrated by conceptually simpler methods in literature outperforming the more complex architectures proposed in this project. I am particularly proud of implementing what I called the robustness measurement framework – it insightfully showed that the graph neural network models did not rely on the similarity metrics as it was expected, naturally suggesting a direction for future work.

\section{Directions for future work}
To make this work more accessible to the wider neuroimaging community, the most important future direction would be to create an interface to the preprocessing pipeline that is agnostic to the downstream analysis task and make it publicly available online.

While it was not practical to do this extension for the UKB dataset that uses its own organisation and preprocessing steps, the preprocessing pipeline could be adapted to work with raw magnetic resonance images, which would make it applicable to many more neuroimaging datasets and parcellations (that would now be a part of the preprocessing framework). This could be especially useful in a more general clinical setting where image acquisition is not standardised and the neuroimaging preprocessing expertise might not be available. 
% The preprocessing framework is also a project that could benefit from good software engineering and computer science skills in order to design a general pipeline that is efficient, flexible and simple to apply to different contexts.

Some parts of the preprocessing component (e.g. fMRI preprocessing) could be extended to use other existing libraries for reproducible research, with this pipeline offered as an extension. In case there are no existing libraries, this pipeline could offer additional methods in a consistent and easy-to-use manner. Support for additional modalities – such as genetic data that has already proved to be useful for neuroimaging tasks~\cite{cole2018brain,parisot2018disease} – could also be implemented.


% TODO: you should mention in your future work that you've used a linear data reduction technique. Given how noisy and non-linear the fMRI is, future work should explore better ways to get a good representation of fmri timeseries, which maybe would help in this prediction task, but out of scope of dissertation
% Apr 23, 2020 1:31 AM
% Tiago Manuel: besides you are backed up by niu's paper saying that fmri might not be useful. but still the reasoning point of linear/non linear interactions maintains

% rb643: Again more for future implementation: I've been playing around with running PCA on the raw time-series as well as Diffusion Embedding on the connectivity matrices and they provide strikingly similar results. Thus is might be computationally efficient to use raw time-series PCA in the future. Generally only the first half dozen PC's are interesting anyway

% Mention Niu et al. 2019 raising the issue that there is systematic bias in brain age gap prediction but not many studies use this knowledge to correct for it. 

% * this pipeline allows to try out more different state-of-the-art GNN architectures and population graphs quickly and efficiently


% * opens up possibilities to incorporating new modalities at scale with growing datasets in the future

% 3) neuroscience findings
% this could be transfer the modular system for the different datasets (HCP)