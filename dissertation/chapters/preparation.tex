\chapter{Preparation}
% Principally, this chapter should describe the work which was undertaken before code was written, hardware built or theories worked on. It should show how the project proposal was further refined and clarified, so that the Implementation stage could go smoothly rather than by trial and error.
% Throughout this chapter and indeed the whole dissertation, it is essential to demonstrate that a proper professional approach was employed.
% The nature of this chapter will vary greatly from one dissertation to another but, underlining the professional approach, this chapter will very likely include a section headed “Requirements Analysis” and incorporate other references to software engineering techniques.
% The chapter will cite any new programming languages and systems which had to be learnt and will mention complicated theories or algorithms which required understanding.
% It is essential to declare the Starting Point (see Section 7). This states any existing codebase or materials that your project builds on. The text here can commonly be identical to the text in your proposal, but it may enlarge on it or report variations. For instance, the true starting point may have turned out to be different from that declared in the proposal and such discrepancies must be explained.

This section describes the main concepts related to the development of the population graph networks, the neuroimaging data they build on, and the neural network architectures that will be used to learn the patterns in those graphs.

\section{Brain age estimation}
\subsection{Rationale behind the brain age}
\textit{what is brain age how does it differ from the chronological age why chronological age can be used to predict the brain age}

\section{Data preprocessing}
% UK Biobank data preprocessed by Dr Richard Bethlehem.

% Describe functional, structural and phenotype features. Brain parcellation atlases. Correlation matrices. Patient exclusion and preprocessing.

% Garbage in, garbage out. Data preprocessing unsurprisingly turned out to be the most difficult and the most important data processing task.

The United Kingdom Biobank (UK Biobank) \cite{sudlow2015uk}. This is a continuous, large, population-wide study of over 500,000 participants containing a wide range of phenotypic and genetic data that is used by the researchers to analyse the risk factors and development of various health conditions. 

Of particular relevance to this dissertation are the UK Biobank participants with neuroimaging data records that have been denoised, motion-corrected and otherwise processed for further analysis, a total of 17,550 participants. The data has been initially preprocessed with the standard UK Biobank pipelines,\footnote{https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf} and further denoised, parcellated and kindly provided by Dr Richard Bethlehem of the Department of Psychiatry.\footnote{Pipelines for preprocessing the UKB dataset at the Department of Psychiatry https://github.com/ucam-department-of-psychiatry/UKB} The details on this processing are described below.


\subsection{Structural data}
Structural brain imaging data encapsulates brain features related to its structure, such as cortical thickness, white 

Combined T1-weighted and T2-weighted FLAIR images which emphasise different aspects of the MRI scan and therefore might help to extract different structural features. For the dataset used in this dissertation, the combination of the two types of images to derive the structural features using the HCP Freesurfer pipeline.\footnote{https://www.ncbi.nlm.nih.gov/pubmed/23668970} 

\subsubsection{Euler indices}
Euler indices are a quality control measure and corresponds to the number of times Freesurfer neuroimaging analysis software failed to connect two slices of the brain image. The higher the Euler index, the worse quality of the scan. These indices might be used to remove the subjects with low-quality scans to avoid them affecting the analysis \cite{kaufmann2019}. Otherwise it can be used as a covariate in a machine learning model (as brain similarity metric or a node feature) to correct for any bias in prediction that might be related to scan quality.

Rafael Romero-Garica (rr480), Lisa Ronan (lr344) and Richard A.I. Bethlehem (rb643)

\subsection{Functional data}
\textit{Turns out functional data is not as effective as structural brain imaging data.}

Description of correlation matrix computation.

\subsection{Parcellation}
A \textit{parcellation} or \textit{atlas} refers to the way the brain is split into meaningful regions for further analysis. Whether two voxels of a brain belong to the same parcel may depend on their proximity, empirical evidence of that the voxels are responsible for the same function and so forth, and can be used to compare the locations in two different brains. When the brain is imaged there is a choice whether to warp the image of the brain to the fixed atlas or whether to warp the atlas to match the variable brain images. The former makes it easier to process a dataset of many images and find the matching regions of two brains faster, but the latter remains more faithful to the unique structure of the individual patient's brain. 

Both functional and structural datasets use one of the most common parcellations by Glasser et al. \cite{glasser2016multi}, which divides the brain into 360 cortical regions and 16 subcortical regions. 

\subsection{Phenotype data}
For the population graph construction, the neuroimaging features are associated with the individual subjects (nodes). The similarity metric is defined by phenotype data, which is all important but not directly neuroimaging-related data. Some examples of phenotype data that is related to the brain include the patient's sex, mental health, other potential health issues, full-time education, bipolar disorder status etc. Indeed the metric that is being predicted is correlated with the brain tissue age indicative of various neurological and neurodegenerative diseases.

\section{Population graphs}


\subsection{Similarity metrics}

\subsection{Computational model}
Train/validation/test split, cross-validation, patient selection and exclusion from results, stratification, graph representation (edge lists, node features, edge features,...)

\section{Multilayer perceptrons}
The multilayer perceptron maths, if appropriate.

\section{Graph convolutional networks}

\section{Graph attention networks}

\section{Requirements analysis}

Tasks to be implemented (according to proposal: work to be done, success criteria, possible extensions), their relative importance (priority) and difficulty. Provide the order in which the tasks should be carried out to show good planning skills and account for the changes in proposal where the preprocessing pipeline turned out to be more important than the neural network implementation.

\section{Software engineering practice}
Implementing a flexible preprocessing pipeline which could be customised in the future for a variety of machine learning tasks even outside graph neural networks (a package).

Modular structure encapsulating specific task and having well defined documentations of the others.

Description of software engineering techniques: planning out and executing the project based on requirements analysis, setting tasks, and smoothly meeting the success criteria.

Code reuse (of open source well tested libraries), follow documentation and follow the PEP-8 style guide (or whatever PyCharm encourages).

Incremental development.

Modular structure: e.g. data processing, graph construction, graph neural network modules, robustness evaluation framework. Figure out where validation and cross validation sections should be (while training, separately etc.)

Diagram of the pipelines and module interaction (like in google design docs)


\section{Choice of tools}
PyTorch, PyTorch geometric extension, graph spectral filters/convolutions, message passing, timeseries preprocessing into correlation matrices, IDEs, backup strategies

\section{Starting point}
\begin{itemize}
    \item dataset, preprocessed by Dr Richard A.I. Bethlehem
    \item PyTorch, PyTorch geometric implementing GCN and GAT APIs and the graph API
    \item no previous experience with graph neural networks or the mathematics behind it
    \item no previous experience with PyTorch; limited experience with machine learning frameworks (basics of TensorFlow), no experience with neuroimaging data
\end{itemize}
