\chapter{Preparation}
% Principally, this chapter should describe the work which was undertaken before code was written, hardware built or theories worked on. It should show how the project proposal was further refined and clarified, so that the Implementation stage could go smoothly rather than by trial and error.
% Throughout this chapter and indeed the whole dissertation, it is essential to demonstrate that a proper professional approach was employed.
% The nature of this chapter will vary greatly from one dissertation to another but, underlining the professional approach, this chapter will very likely include a section headed “Requirements Analysis” and incorporate other references to software engineering techniques.
% The chapter will cite any new programming languages and systems which had to be learnt and will mention complicated theories or algorithms which required understanding.
% It is essential to declare the Starting Point (see Section 7). This states any existing codebase or materials that your project builds on. The text here can commonly be identical to the text in your proposal, but it may enlarge on it or report variations. For instance, the true starting point may have turned out to be different from that declared in the proposal and such discrepancies must be explained.

%  ~2,500 words

This section presents in more depth the brain age estimation method (Section \ref{brain-age-estimation}), the multiple data modalities that will be used for the brain age estimation task (Section \ref{dataset}), the population graphs (Section \ref{population-graphs}), and the neural network architectures that will be used to train the population graphs (Sections \ref{training-gcn} and \ref{training-gat}).

% In addition it presents the requirements to the implementation of this project and the software engineering principles that have been used to ensure 

\section{Brain age estimation}
\label{brain-age-estimation}
TODO this sounds extremely confusing (the concept itself is confusing)

To estimate the brain age gap the difference between the chronological and the brain age must be known. The common technique is to develop a machine learning method to estimate the chronological age from the brain imaging features. The estimated age is then considered to be the brain age although it has been trained to estimate the chronological age and the actual value of the brain age is never known. The reason is why it works... \cite{niu2019improved}

We represent the brain age $y_b$ as the sum of the known chronological age $y_c$ and the unknown brain age gap $\varepsilon_g$:

\begin{equation}
    y_b = y_c + \varepsilon_g.
\end{equation}

On the other hand, the machine learning model estimates the brain age $y_b$ from some function of the brain imaging features $X$ and a prediction error $\varepsilon_e$:

\begin{equation}
    y_b = f(X) + \varepsilon_e.    
\end{equation}

Expressing $y_c$ as $y_b - \varepsilon_g$ and substituting the previous result, we get the estimate of chronological age as

\begin{equation}
    y_c = f(X) + \varepsilon_g - \varepsilon_e,
\end{equation}

Since the machine learning models estimate chronological age as a function of brain imaging features (with some estimation error $\varepsilon_e'$)

\begin{equation}
    y_c = f(X) + \varepsilon_e',
\end{equation}

the error of the proposed machine learning model $\varepsilon_e'$ will contain in itself both the brain age gap $\varepsilon_g$ (which we are interested in) and the brain age prediction error $\varepsilon_e$.

It is out of scope of this dissertation to prove that the brain age gap component $\varepsilon_g$ is larger than the error term; however, the keen reader is referred to Niu et al. \cite{niu2019improved} where this is verified through correlation of the brain age gaps to the cognitive behaviour scores.

\section{Neuroimaging dataset}
\label{dataset}

\subsection{United Kingdom Biobank}

The United Kingdom Biobank (UK Biobank) \cite{sudlow2015uk} is a continuous, large, population-wide study of over 500,000 participants containing a wide range of phenotypic and genetic data that is used by the researchers to analyse the risk factors and development of various health conditions. 

Of particular relevance to this dissertation are the UK Biobank participants with neuroimaging data records that have been denoised, motion-corrected and otherwise processed for further analysis, a total of 17,550 participants. The data has been initially preprocessed with the standard UK Biobank pipelines,\footnote{\url{https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf}} and further denoised, parcellated and kindly provided by Dr Richard Bethlehem of the Department of Psychiatry. The Department of Psychiatry pipelines have been co-authored with Dr Rafael Romero-Garcia and Dr Lisa Ronan.\footnote{\url{https://github.com/ucam-department-of-psychiatry/UKB}} The details on the neuroimaging dataset are described below.

\subsection{Parcellation}
A \textit{parcellation} or \textit{atlas} refers to the way the brain is split into meaningful regions for further analysis. Whether two voxels of a brain belong to the same parcel may depend on their proximity, empirical evidence of that the voxels are responsible for the same function and so forth, and can be used to compare the locations in two different brains. When the brain is imaged there is a choice whether to warp the image of the brain to the fixed atlas or whether to warp the atlas to match the variable brain images. The former makes it easier to process a dataset of many images and find the matching regions of two brains faster, but the latter remains more faithful to the unique structure of the individual patient's brain. 

Both functional and structural datasets use one of the most common parcellations by Glasser et al. \cite{glasser2016multi}, which divides the brain into 360 cortical regions and 16 subcortical regions. 

\subsection{Structural data}
Structural brain imaging data encapsulates brain features related to its structure, such as cortical thickness, white 

Combined T1-weighted and T2-weighted FLAIR images which emphasise different aspects of the MRI scan and therefore might help to extract different structural features. For the dataset used in this dissertation, the combination of the two types of images to derive the structural features using the HCP Freesurfer pipeline.\footnote{\url{https://www.ncbi.nlm.nih.gov/pubmed/23668970}} 

\subsection{Euler indices}
Euler index\footnote{\url{https://www.ncbi.nlm.nih.gov/pubmed/29278774}} is a quality control metric and corresponds to the number of times the Freesurfer brain reconstruction software failed to connect two slices of an MRI image. The higher the Euler index, the worse is the quality of the scan. Euler indices might be used to remove the subjects with low-quality scans to avoid them affecting the analysis \cite{kaufmann2019}. Otherwise they can be used as a covariate in a machine learning model (as brain similarity metric or a node feature) to correct for any bias in prediction that might be related to scan quality.

\subsection{Functional data}
The resting state functional MRI (rs-fMRI) is the representation of the brain activity over time. In MRI scanner this is measured by the changes in blood oxygenation as neural activity regulates the oxygen demand, resulting in \textit{blood oxygenation level dependent} (BOLD) time-series measured at each voxel of the brain.

TODO \textit{figure of BOLD timeseries}

We are interested in estimating which parts of the brain are connected to each other, which we do by making use of the assumption that parts of the brain that have related function would also have similar activity patterns. As a consequence, we would expect higher correlation of the corresponding BOLD time-series. For time-series $T_1$ and $T_2$, \textit{Pearson's correlation} (denoted as $r$) is computed as

\begin{equation}
    r(T_1, T_2) = \frac{\mathrm{cov}(T_1, T_2)}{\sigma_{T_1} \sigma_{T_2}}
\end{equation}

where $\mathrm{cov}(\cdot, \cdot)$ denotes covariance and $\sigma$ stands for standard deviation.

% TODO (Pearson's, lasso, partial correlation, covariance)
% Tiago's observation that partial correlation may give better results when including functional MRI time-series in the machine learning model.
% From wiki on partial correlation: In probability theory and statistics, partial correlation measures the degree of association between two random variables, with the effect of a set of controlling random variables removed. If we are interested in finding whether or to what extent there is a numerical relationship between two variables of interest, using their correlation coefficient will give misleading results if there is another, confounding, variable that is numerically related to both variables of interest. This misleading information can be avoided by controlling for the confounding variable, which is done by computing the partial correlation coefficient. This is precisely the motivation for including other right-side variables in a multiple regression; but while multiple regression gives unbiased results for the effect size, it does not give a numerical value of a measure of the strength of the relationship between the two variables of interest.

This (or other correlation types) to derive the \textit{functional connectivity matrix} that stores the pairwise correlations between the different voxels as the overall representation of functional brain connectivity. For time-series $T_1, \dots, T_N$,

\begin{equation}
    \mathrm{fcm}(T_1, \dots, T_N) = \begin{bmatrix}
        r(T_1, T_1) & \cdots & r(T_1, T_N) \\
        \vdots & \ddots & \vdots \\
        r(T_N, T_1) & \cdots & r(T_N, T_N)
    \end{bmatrix},
\end{equation}

of which (due to symmetry and the non-informative diagonal) only the flattened lower triangle is usually used for the machine learning implementations.

\subsection{Phenotype data}
For the population graph construction, the neuroimaging features are associated with the individual subjects (nodes). The similarity metric is defined by phenotype data, which is all important but not directly neuroimaging-related data. Some examples of phenotype data that is related to the brain include the patient's sex, mental health, other potential health issues, full-time education, bipolar disorder status etc. Indeed the metric that is being predicted is correlated with the brain tissue age indicative of various neurological and neurodegenerative diseases.

TODO \textit{a table of the actual phenotypes used when the results are ready}

\section{Population graphs}
\label{population-graphs}
% TODO connection between the subject set S and vertex set V through S_v or something, i.e. connect subject and vertex sets in a clearer way.

We connect the multi-modal MRI imaging (structural and/or functional), quality control and phenotype data of the set of patients $S$ into a sparse \textit{population graph} $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$, where $\mathcal{V}$ is the set of graph vertices (with one vertex uniquely representing one patient), and $\mathcal{E}$ is the set of edges (representing the \textit{similarity} of patients).

Each vertex $v \in \mathcal{V}$ is the vector containing the individual subject's neuroimaging data, whether structural, functional, or both. The edge $(v, w) \in \mathcal{E}$ connects patients $v$ and $w$ based on phenotypic similarity that is defined by some \textit{similarity metric} as described below.

\subsection{Similarity metrics}
The topology of the graph is determined by a similarity metric that uses the non-imaging (phenotypic) information of the subjects to create connections between the nodes containing brain imaging data. Defining a good similarity metric is important to correct for the confounding effects on the feature vectors (for example, subject's sex has an impact on the brain volume) as well as to cluster patients into the most informative neighbourhoods where the predicted variable (brain age) explains the most variance in node features.

Similarity metrics are defined using some \textit{similarity function} $\mathrm{sim}(\cdot, \cdot)$ which takes two subjects and returns the similarity score between them (the higher the score, the more similar the subjects):

\begin{equation}
    \mathrm{sim}(S_v, S_w) = \frac{1}{n}\sum_{i=1}^{n} \mathbf{1}[M_i(v) = M_i(w)].
\end{equation}

Here $\{M_1, \dots, M_n\}$ is a set of phenotypic metrics that are used in computing subject similarity (such as sex, mental health, fluid intelligence score etc.) and $\mathbf{1}[\cdot]$ is an indicator function, in this case returning a non-zero value when values for a given phenotypic feature $M_i$ match for two subjects $S_v$ and $S_w$.

TODO \textit{Qualitative (categorial) metrics can be defined as Kronecker delta $\delta$ and quantitative (numerical) metrics have an indicator whether the distance between values $M_i(v)$ and $M_i(w)$ is within some $\epsilon$.}

To avoid memory issues when $|\mathcal{E}| \sim O(|\mathcal{V}|^2)$ and minimise the size of the neighbourhood to only the highly similar subjects, a \textit{similarity threshold} $\theta$ is defined such that

\begin{equation}
    (S_v, S_w) \in \mathcal{E} \iff \mathrm{sim}(S_v, S_w) \geq \theta.
\end{equation}

\subsection{Training task}
% Train/validation/test split, cross-validation, patient selection and exclusion from results, stratification, graph representation (edge lists, node features, edge features,...)
\cite{kipf2017semi}: The task is to predict the label of the nodes, where the labels are visible only for the training and validation but not the test nodes. Semi-supervised learning allows the label information and parameter weights to spread to node neighbourhoods to the similar nodes as defined by the similarity metric, 

A population graph is trained in a \textit{semi-supervised} manner. This means that the entire dataset (all nodes and all labels) is included in the graph. At each training step (\textit{epoch}), the parameters for all nodes are updated but only based on the feedback from training and validation nodes. The final predictive power of the model is evaluated based on its performance on previously hidden test node labels.

Labels are available for a small subset of nodes and are spread across neighbourhoods through a regularisation term such as Laplacian \cite{kipf2017semi}, predicting the labels for the remaining nodes

TODO \textit{an illustration of the graph with marked training and validation nodes with visible labels and how the training happens on those followed by how the graph is evaluated on the test nodes where the parameters were updated but the labels never seen}


\section{Graph convolutional networks}
\label{training-gcn}
TODO Graph definition through degree and adjacency matrices, the weights of the edges being binary (either no edge or a weight-1 edge). Graph Laplacian. Diagonalisation of Laplacian matrix because it's positive semi-definite. Spatial vs spectral graph domains. Graph Fourier transform. Fourier transform as transformation to the eigenbasis obtained through graph Laplacian diagonalisation. Note that the basis depends completely on the graph structure and slight permutation can change the eigenbasis. Graph convolution with a filter $g$ as multiplication of signal and filter in the Fourier domain. Parametric and non-parametric convolution filters using this $g_\theta$; what does $\theta$ mean in relation to the Fourier coefficients; what exactly Fourier coefficients refer to. Eigenvalues as graph frequencies and learning as a low-pass filter of frequencies. Approximation of the Laplacian diagonalisation with Chebyshev polynomials (ChebNet) with the convolution defined for $k$-th order polynomials corresponding to $k$ hops across neighbourhood. \cite{defferrard2016convolutional} Kipf and Welling simplifying ChebNet hops as stacking single-hop layers and using renormalisation trick for the node to use the most information from itself. \cite{kipf2017semi} Averaging representations of neighbour features and smoothing labels as a consequence. \cite{wu2019simplifying} (this citation also very good for follow through for what the training is doing for all layers in general rather than a single feature vector, i.e. the training flow); can also mention \cite{wu2019comprehensive}; convolution on regular vs irregular grids (i.e. intro to simple convolution before carrying on?); \cite{defferrard2016convolutional}: "convolution is linear operator that diagonalises in the fourier domain represented by the eigenvectors of the Laplacian operator"




\cite{velickovic2018graph}: graph definition in the Fourier domain based on the eigendecomposition of the graph Laplacian, filters further approximated by Chebyshev expansion of the graph Laplacian avoiding the expensive eigendecomposition operation (ChebNet); further improvements by filter restriction to local neighbourhoods and stacking them if necessary 

\subsection{Graph Fourier transform}


\section{Graph attention networks}
\label{training-gat}
\cite{velickovic2018graph} More based on the non-spectral (i.e. spatial) approaches where an operator is defined to work on the neighbourhoods of different sizes, maintaining the weight sharing property (usually done by defining a separate operator on the neighbourhoods of those sizes).


\textit{Self-attention} is also added in to the concept where different parts of the node's neighbourhood are considered with different importance weights, getting a representation of the rest of the neighbourhood. 


\subsection{Graph attentional layer}
For the layer of an $N$-node graph with $F$ input and $F'$ output features, 

input node features $\{\mathbf{h_1}, \dots, \mathbf{h_N}\}, \mathbf{h_i} \in \mathbb{R}^F$

output node features $\{\mathbf{h_1'}, \dots, \mathbf{h_N'}\}, \mathbf{h_i'} \in \mathbb{R}^{F'}$

linear transformation with weight matrix $\mathbf{W} \in \mathbb{R}^{F' \times F}$

self attention $a: \mathbb{R}^{F'} \times \mathbb{R}^{F'} \rightarrow \mathbb{R}$

attention coefficients \textit{can already include neighbourhoods} $e_{ij} = a(\mathbf{W}\mathbf{h}_i, \mathbf{W}\mathbf{h}_j)$



weight vector $\mathbf{a} \in \mathbb{R}^{2F'}$

\begin{align}
    \alpha_{ij} &= \mathrm{softmax}_j(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_j]) \\
    &=  \frac{\mathrm{exp}(\sigma_1(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_j]))}{\sum\limits_{k \in \mathcal{N}_i}\mathrm{exp}(\sigma_1(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_k]))}
\end{align}

where $\alpha_{ij}$ is the attention coefficient for an edge $i\leadsto j$ (corresponding to the importance of features in node $j$ to the features in node $i$), normalised across $i$'s neighbourhood $\mathcal{N}_i$ (defined as e.g. all nodes one hop away); $\sigma_1$ is a non-linearity. $\parallel$ means concatenation

The coefficients $\alpha_{ij}$ and the weight matrix are used to compute the output features:

\begin{equation}
    \mathbf{h}_i' = \sigma(\sum\limits_{k \in \mathcal{N}_i} \alpha_{ij}\mathbf{W}\mathbf{h}_j)\label{eq:2.11}
\end{equation}

\subsection{Multiple attention}
The above attention mechanism can be repeated several times to stabilise the performance, where one independent application of attention is called and attention head. The outputs of the independent attention heads are concatenated together until the last layer when they are averaged into a single output. For $K$ attention heads, the results of \eqref{eq:2.11} are concatenated:

\begin{equation}
    \mathbf{h}_i' = \big\|_{k=1}^{K} \sigma(\sum\limits_{k \in \mathcal{N}_i} \alpha_{ij}^k\mathbf{W}^k\mathbf{h}_j)
\end{equation}

Which is averaged in the last layer:

\begin{equation}
    \mathbf{h}_i' = \sigma(\frac{1}{K}\sum\limits_{k=1}^K\sum\limits_{j \in \mathcal{N}_i} \alpha_{ij}^k\mathbf{W}^k\mathbf{h}_j).
\end{equation}

TODO Talk about the initial features, \textit{diagram of the attention heads I guess} etc.


\section{Requirements analysis}

Tasks to be implemented (according to proposal: work to be done, success criteria, possible extensions), their relative importance (priority) and difficulty. Provide the order in which the tasks should be carried out to show good planning skills and account for the changes in proposal where the preprocessing pipeline turned out to be more important than the neural network implementation.

\section{Software engineering practice}
Implementing a flexible preprocessing pipeline which could be customised in the future for a variety of machine learning tasks even outside graph neural networks (a package).

Modular structure encapsulating specific task and having well defined documentations of the others.

Description of software engineering techniques: planning out and executing the project based on requirements analysis, setting tasks, and smoothly meeting the success criteria.

Code reuse (of open source well tested libraries), follow documentation and follow the PEP-8 style guide (or whatever PyCharm encourages).

Incremental development.

Modular structure: e.g. data processing, graph construction, graph neural network modules, robustness evaluation framework. Figure out where validation and cross validation sections should be (while training, separately etc.)

Diagram of the pipelines and module interaction (like in google design docs)


\section{Choice of tools}
PyTorch, PyTorch geometric extension, graph spectral filters/convolutions, message passing, time-series preprocessing into correlation matrices, IDEs, backup strategies

\section{Starting point}
\begin{itemize}
    \item dataset, preprocessed by Dr Richard A.I. Bethlehem
    \item PyTorch, PyTorch geometric implementing GCN and GAT APIs and the graph API
    \item no previous experience with graph neural networks or the mathematics behind it
    \item no previous experience with PyTorch; limited experience with machine learning frameworks (basics of TensorFlow), no experience with neuroimaging data
\end{itemize}
