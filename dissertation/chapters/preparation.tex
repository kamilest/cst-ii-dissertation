\chapter{Preparation}
% Principally, this chapter should describe the work which was undertaken before code was written, hardware built or theories worked on. It should show how the project proposal was further refined and clarified, so that the Implementation stage could go smoothly rather than by trial and error.
% Throughout this chapter and indeed the whole dissertation, it is essential to demonstrate that a proper professional approach was employed.
% The nature of this chapter will vary greatly from one dissertation to another but, underlining the professional approach, this chapter will very likely include a section headed “Requirements Analysis” and incorporate other references to software engineering techniques.
% The chapter will cite any new programming languages and systems which had to be learnt and will mention complicated theories or algorithms which required understanding.
% It is essential to declare the Starting Point (see Section 7). This states any existing codebase or materials that your project builds on. The text here can commonly be identical to the text in your proposal, but it may enlarge on it or report variations. For instance, the true starting point may have turned out to be different from that declared in the proposal and such discrepancies must be explained.

%  ~2,500 words

This section presents in more depth the brain age estimation method (Section \ref{brain-age-estimation}) and the multiple data modalities that will be used for the brain age estimation task (Section \ref{dataset}). It also discusses population graphs (Section \ref{population-graphs}) and the neural network architectures that will be used to train them (Sections \ref{training-gcn} and \ref{training-gat}).

\section{Brain age estimation}
\label{brain-age-estimation}

Similar to the model proposed in Niu et al. \cite{niu2019improved}, we express the \textit{brain age} ($y_b$) as the sum of the known \textit{chronological age} ($y_c$) and the unknown \textit{brain age gap} ($\varepsilon_g$):

\begin{equation}
    \label{brainage:eq1}
    y_b = y_c + \varepsilon_g.
\end{equation}

The brain age gap estimation methodologies (such as \textit{BrainAGE} \cite{franke2019ten}) assume that for healthy subjects in the general population the brain age corresponds to chronological age:

\begin{equation}
    \label{brainage:assume}
    y_b \approx y_c,\quad \varepsilon_g \text{ small}.
\end{equation}

Our goal is to estimate the brain age $y_b$ by fitting some function $f$ of the brain imaging features $X$. It will give a prediction error $\varepsilon_e$:

\begin{equation}
    \label{brainage:eq2}
    y_b = f(X) + \varepsilon_e.
\end{equation}

From Equations \ref{brainage:eq1} and \ref{brainage:eq2}, the estimate of chronological age is, on the other hand,

\begin{align}
    y_c &= f(X) + \varepsilon_e - \varepsilon_g \\
        \label{brainage:eq3}
        &= f(X) + \varepsilon.
\end{align}

Since the true brain age is unknown, any (semi-)supervised machine learning model can only work on chronological age labels following Equation \ref{brainage:eq3}, where the prediction error $\varepsilon$ contains both the brain age gap $\varepsilon_g$ and the brain age estimation error $\varepsilon_e$. However, the assumption in Equation \ref{brainage:assume} still permits learning the brain age function $f$ as long as the model is trained only on healthy subjects, so that $\varepsilon \approx \varepsilon_e$. When the same model is applied to subjects with various brain health conditions, the errors outside of the $\varepsilon_e$ could be assumed to come from the brain age gap.  

An alternative method, which does not restrict training data only to healthy subjects, is proposed in Niu et al. \cite{niu2019improved}. However, it requires experimentally verifying (e.g. through subjects' performance in cognitive behaviour tests) that $\varepsilon$ depends primarily on the brain age gap $\varepsilon_g$ and not the brain age prediction error $\varepsilon_e$, which is out of scope of this dissertation.

\section{Neuroimaging dataset}
\label{dataset}

\subsection{United Kingdom Biobank}

The United Kingdom Biobank (UK Biobank) \cite{sudlow2015uk} is a continuous population-wide study of over 500,000 participants containing a wide range of phenotypic and genetic data. 
Of particular relevance to this dissertation are the UK Biobank participants with neuroimaging data records, a total of 17,550 participants.
The MRI scan data of those patients has been initially processed (denoised and motion-corrected) with the standard UK Biobank pipelines,\footnote{\url{https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf}} and further parcellated at the Department of Psychiatry by Dr Richard Bethlehem, Dr Rafael Romero-Garcia and Dr Lisa Ronan.\footnote{\url{https://github.com/ucam-department-of-psychiatry/UKB}} The details related to this neuroimaging dataset are described below.

\subsection{Parcellation}
A \textit{parcellation} or \textit{atlas} refers to the way the brain voxels are split into meaningful regions depending on their proximity, empirical evidence of them being responsible for the same function and so forth. This compresses the high dimensional per-voxel measurements into per-parcel summaries of much lower dimension, the latter being easier to manage in further analysis.

% When the brain is imaged there is a choice whether to warp the image of the brain to the fixed atlas or whether to warp the atlas to match the variable brain images. The former makes it easier to process a dataset of many images and find the matching regions of two brains faster, but the latter remains more faithful to the unique structure of the individual patient's brain. 

Both structural and functional datasets in this dissertation will use one of the most common parcellations, developed by Glasser et al. \cite{glasser2016multi}, which divides the brain into 360 cortical regions and 16 subcortical regions. 

\subsection{Structural data}
Structural brain imaging data refers to cortical thickness, surface area and gray matter volume, reported at parcel granularity.

These features have been derived from two types of an MRI image called T1-weighted and T2-weighted FLAIR, where each type emphasises different aspects of the scan and highlights some features more than the others. The image processing has been done using the HCP Freesurfer pipeline.\footnote{\url{https://www.ncbi.nlm.nih.gov/pubmed/23668970}} 

% The images emphasise different aspects of the MRI scan a. For the dataset used in this dissertation, the combination of the two types of images to derive the structural features 

\subsection{Euler indices}
Euler index\footnote{\url{https://www.ncbi.nlm.nih.gov/pubmed/29278774}} is a quality control metric which corresponds to the number of times the Freesurfer brain reconstruction software failed to seamlessly connect two 2D slices of an MRI image into the 3D model of the brain. The higher the Euler index, the worse is the quality of the scan. Euler indices might be used to remove the subjects with low-quality scans to avoid them affecting the analysis \cite{kaufmann2019}. Alternatively, they can be used as a covariate in a machine learning model (as a brain similarity metric or a node feature) to correct for any bias in prediction that might be related to scan quality.

\subsection{Functional data}
The resting state functional MRI (rs-fMRI) represents brain activity over time. In the MRI scanner this is measured through \textit{blood oxygenation level dependent} (BOLD) time-series, which represent the changes in blood oxygenation of brain vessels as neural activity regulates the oxygen demand. The time-series are reported at parcel level as an average of all time series of voxels belonging to the same parcel.

% well, you really have to think if [BOLD timeseries] are useful at all for understanding. If you just say it's timeseries, maybe a picture with timeseries of 3 brain regions could just illustrate how the timeseries look like (I mean, it's useful in the sense that people see how the timeseries is/behaves in a few regions). But if you don't use them, then there's no point, and maybe is better to show how the correlation matrix looks like for one person

We are interested in estimating which parts of the brain are connected to each other, which we do by making use of the assumption that \textit{parts of the brain that have related functions would also have similar activity patterns}. As a consequence, we would expect higher correlation of the corresponding BOLD time-series. For time-series $T_1$ and $T_2$, \textit{Pearson's correlation} (denoted as $r$) is computed as

\begin{equation}
    r(T_1, T_2) = \frac{\mathrm{cov}(T_1, T_2)}{\sigma_{T_1} \sigma_{T_2}}
\end{equation}

where $\mathrm{cov}(\cdot, \cdot)$ denotes covariance and $\sigma$ stands for standard deviation.

% Could include (Pearson's, lasso, partial correlation, covariance) -- but these are not used?

% Tiago's observation that partial correlation may give better results when including functional MRI time-series in the machine learning model.
% From wiki on partial correlation: In probability theory and statistics, partial correlation measures the degree of association between two random variables, with the effect of a set of controlling random variables removed. If we are interested in finding whether or to what extent there is a numerical relationship between two variables of interest, using their correlation coefficient will give misleading results if there is another, confounding, variable that is numerically related to both variables of interest. This misleading information can be avoided by controlling for the confounding variable, which is done by computing the partial correlation coefficient. This is precisely the motivation for including other right-side variables in a multiple regression; but while multiple regression gives unbiased results for the effect size, it does not give a numerical value of a measure of the strength of the relationship between the two variables of interest.

The correlations are used to derive the \textit{functional connectivity matrix} storing pairwise correlations between the different voxels (or parcels) as the overall representation of functional brain connectivity. For time-series $T_1, \dots, T_N$,

\begin{equation}
    \mathrm{fcm}(T_1, \dots, T_N) = \begin{bmatrix}
        r(T_1, T_1) & \cdots & r(T_1, T_N) \\
        \vdots & \ddots & \vdots \\
        r(T_N, T_1) & \cdots & r(T_N, T_N)
    \end{bmatrix},
\end{equation}

of which (due to symmetry and the non-informative diagonal) only the flattened lower triangle is usually used as input for the machine learning models.

\subsection{Phenotype data}

In this dissertation, the phenotype data is defined as all subject data that does not come from MRI scans. The features related to this project include the subject's sex, the psychiatric disorder diagnoses, mental health status, education and so forth.

The purpose of phenotype data is to define the inter-subject similarity score, which will determine the edges in the population graph. This is further discussed in the next section. The full list of features that were used to define similarity metrics is provided in the Appendix.

TODO Appendix.

\section{Population graphs}
\label{population-graphs}

The multi-modal MRI imaging (structural, functional, quality control) and phenotypic data of the set of patients $S$ can be connected into a undirected \textit{population graph} $G = (V, E)$, where $V$ is the set of graph nodes (with one node uniquely representing one subject), and $E$ is the set of edges (representing the similarity of subjects).

Each node $v \in V$ is the vector containing the individual subject's neuroimaging data, whether structural, functional, or both. The edge $(v, w) \in E$ connects subjects $s_v, s_w \in S$ based on phenotypic similarity, defined by some similarity metric.

\subsection{Similarity metrics}
The topology of the graph is determined by a similarity metric that uses the non-imaging (phenotypic) information of the subjects to create edges between the nodes with brain imaging data. Defining a good similarity metric is important to correct for the confounding effects on the feature vectors (for example, the subject's sex affects the brain volume) as well as to cluster subjects into the most informative neighbourhoods. For example, in this dissertation the neighbourhoods that have similar brain age gaps could be useful.

Similarity metrics are defined using a \textit{similarity function} $\mathrm{sim}(\cdot, \cdot)$ which takes two subjects and returns the similarity score between them (the higher the score, the more similar are the subjects):

\begin{equation}
    \mathrm{sim}(s_v, s_w) = \frac{1}{n}\sum_{i=1}^{n} \mathbf{1}[M_i(s_v) = M_i(s_w)].
\end{equation}

Here $\{M_1, \dots, M_n\}$ is a set of phenotypic metrics that are used to compute subject similarity and $\mathbf{1}[\cdot]$ is an indicator function, in this case returning a non-zero value when values for a given phenotypic feature $M_i$ match for two subjects $s_v$ and $s_w$. (In practice, if the metric is floating point, ``matching'' could be defined in terms of phenotypic metrics being within some constant $\epsilon$.) 

To avoid memory issues when $|E| \sim O(|V|^2)$ and minimise the size of the neighbourhood to only highly similar subjects, a \textit{similarity threshold} $\theta$ is used such that

\begin{equation}
    (v, w) \in E \iff \mathrm{sim}(s_v, s_w) \geq \theta.
\end{equation}

\subsection{Training task}
% Train/validation/test split, cross-validation, patient selection and exclusion from results, stratification, graph representation (edge lists, node features, edge features,...)

% Labels are available for a small subset of nodes and are spread across neighbourhoods through a regularisation term such as Laplacian \cite{kipf2017semi}, predicting the labels for the remaining nodes

For node label prediction tasks such as brain age prediction, population graphs are trained in a \textit{semi-supervised} manner: while the entire dataset (every node and edge) is included in the graph, the labels are available only for a subset of nodes~\cite{kipf2017semi}. At each training step, the feedback from nodes with available labels is used to update the parameters for the entire graph, which could be seen as information being ``propagated'' from a labelled node to the neighbours that are similar to it (as defined by the similarity metric). After the model is trained, every node in the population graph has a prediction for its label. The predictive power of a model can be evaluated based on its performance for a set of test nodes, for which the labels had been known but invisible to the model at the training stage.


% TODO \textit{an illustration of the graph with marked training and validation nodes with visible labels and how the training happens on those followed by how the graph is evaluated on the test nodes where the parameters were updated but the labels never seen} – maybe include in GCN/GAT sections instead?


\section{Graph convolutional networks}
\label{training-gcn}
% What is actually essential about the graph convolutional networks?

To make the computation independent of (irregular) graph topology, the graph is first transformed from spatial (Euclidean) to spectral (Fourier) domain. The more expensive convolution operation in the Euclidean domain corresponds to a cheaper multiplication operation in the Fourier domain.

\subsection{Graph spectral decomposition}

In spectral analysis, a graph $G = (V, E)$ is represented by its \textit{normalised Laplacian} matrix~\cite{defferrard2016convolutional}: 

\begin{equation}
    \mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2}\mathbf{A}\mathbf{D}^{-1/2},
\end{equation}

where $\mathbf{I}$ is the identity matrix, $\mathbf{D} \in \mathbb{N}^{|V| \times |V|}$ is the diagonal degree matrix of the graph nodes, and $\mathbf{A} \in \{0, 1\}^{|V| \times |V|}$ is the adjacency matrix such that $a_{ij} = \mathbf{1}[(i, j) \in E]$. The Laplacian uniquely represents the graph as it is based on the graph's topology.

The positive semidefinite Laplacian matrix is decomposed as

\begin{equation}
    \mathbf{L} = \mathbf{U\Lambda U}^\mathrm{T},
\end{equation}

where $\mathbf{\Lambda}$ is the diagonal eigenvalue matrix, and $\mathbf{U}$ is the eigenbasis defining the graph Fourier domain: for a signal $\mathbf{x} \in \mathbb{R}^{n}$ (e.g. features of some node), $\mathbf{\hat{x}} = \mathbf{U}^\mathrm{T}\mathbf{x}$ is the \textit{graph Fourier transform} of $\mathbf{x}$, and $\mathbf{x} = \mathbf{U}\mathbf{\hat{x}}$ is its inverse~\cite{wu2019simplifying}.

% Eigenvalues as graph frequencies and learning as a low-pass filter of frequencies.
% Fourier transform as transformation to the eigenbasis obtained through graph Laplacian diagonalisation.

% \cite{velickovic2018graph}: graph definition in the Fourier domain based on the eigendecomposition of the graph Laplacian

\subsection{Spectral graph convolution}

For a filter $\mathbf{g} \in \mathbb{R}^m$ with $\mathbf{\hat{G}} = \mathrm{diag}(\mathbf{U}^\mathrm{T}\mathbf{g})$ a diagonal matrix containing the filter's spectral coefficients, the graph convolution of a signal $\mathbf{x}$ is defined as

\begin{equation}
    \mathbf{x} *_G \mathbf{g} = \mathbf{U}((\mathbf{U}^\mathrm{T}\mathbf{x}) \odot (\mathbf{U}^\mathrm{T}\mathbf{g})) = \mathbf{U}\mathbf{\hat{G}}\mathbf{U}^\mathrm{T}\mathbf{x}
\end{equation}

where $\odot$ is the element-wise (Hadamard) product~\cite{wu2019simplifying}.

\subsection{Approximating graph convolution}
To avoid the computationally expensive eigendecomposition of the graph Laplacian and the $O(n^2)$ matrix-vector multiplication while switching between spatial and Fourier domains, the Laplacian diagonalisation $??$ can be approximated by Chebyshev polynomials:

% ChebNet: filters further approximated by Chebyshev expansion of the graph Laplacian avoiding the expensive eigendecomposition operation (ChebNet) (velickovic)

\begin{equation}
    Chebyshev polynomials
\end{equation}

where the convolution defined for the $k$-th order polynomials corresponds to the neighbourhood within $k$ hops (or $k$ hops away??) from the node of interest \cite{defferrard2016convolutional}.

Kipf and Welling \cite{kipf2017semi} simplifying ChebNet hops as stacking single-hop layers and using renormalisation trick for the node to use the most information from itself. 
% Velickovic: further improvements by filter restriction to local neighbourhoods and stacking them if necessary 

Averaging representations of neighbour features and smoothing labels as a consequence. \cite{wu2019simplifying}
% (this citation also very good for follow through for what the training is doing for all layers in general rather than a single feature vector, i.e. the training flow)
% can also mention \cite{wu2019comprehensive};


% extension: an alternative to Chebyshev polynomials (extension)

\section{Graph attention networks}
\label{training-gat}
\cite{velickovic2018graph} More based on the non-spectral (i.e. spatial) approaches where an operator is defined to work on the neighbourhoods of different sizes, maintaining the weight sharing property (usually done by defining a separate operator on the neighbourhoods of those sizes).


\textit{Self-attention} is also added in to the concept where different parts of the node's neighbourhood are considered with different importance weights, getting a representation of the rest of the neighbourhood. 


\subsection{Graph attentional layer}
For the layer of an $N$-node graph with $F$ input and $F'$ output features, 

input node features $\{\mathbf{h_1}, \dots, \mathbf{h_N}\}, \mathbf{h_i} \in \mathbb{R}^F$

output node features $\{\mathbf{h_1'}, \dots, \mathbf{h_N'}\}, \mathbf{h_i'} \in \mathbb{R}^{F'}$

linear transformation with weight matrix $\mathbf{W} \in \mathbb{R}^{F' \times F}$

self attention $a: \mathbb{R}^{F'} \times \mathbb{R}^{F'} \rightarrow \mathbb{R}$

attention coefficients \textit{can already include neighbourhoods} $e_{ij} = a(\mathbf{W}\mathbf{h}_i, \mathbf{W}\mathbf{h}_j)$



weight vector $\mathbf{a} \in \mathbb{R}^{2F'}$

\begin{align}
    \alpha_{ij} &= \mathrm{softmax}_j(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_j]) \\
    &=  \frac{\mathrm{exp}(\sigma_1(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_j]))}{\sum\limits_{k \in \mathcal{N}_i}\mathrm{exp}(\sigma_1(\mathbf{a}^T[\mathbf{W}\mathbf{h}_i \parallel \mathbf{W}\mathbf{h}_k]))}
\end{align}

where $\alpha_{ij}$ is the attention coefficient for an edge $i\leadsto j$ (corresponding to the importance of features in node $j$ to the features in node $i$), normalised across $i$'s neighbourhood $\mathcal{N}_i$ (defined as e.g. all nodes one hop away); $\sigma_1$ is a non-linearity. $\parallel$ means concatenation

The coefficients $\alpha_{ij}$ and the weight matrix are used to compute the output features:

\begin{equation}
    \mathbf{h}_i' = \sigma(\sum\limits_{k \in \mathcal{N}_i} \alpha_{ij}\mathbf{W}\mathbf{h}_j)\label{eq:2.11}
\end{equation}

\subsection{Multiple attention}
The above attention mechanism can be repeated several times to stabilise the performance, where one independent application of attention is called and attention head. The outputs of the independent attention heads are concatenated together until the last layer when they are averaged into a single output. For $K$ attention heads, the results of \eqref{eq:2.11} are concatenated:

\begin{equation}
    \mathbf{h}_i' = \big\|_{k=1}^{K} \sigma(\sum\limits_{k \in \mathcal{N}_i} \alpha_{ij}^k\mathbf{W}^k\mathbf{h}_j)
\end{equation}

Which is averaged in the last layer:

\begin{equation}
    \mathbf{h}_i' = \sigma(\frac{1}{K}\sum\limits_{k=1}^K\sum\limits_{j \in \mathcal{N}_i} \alpha_{ij}^k\mathbf{W}^k\mathbf{h}_j).
\end{equation}

TODO Talk about the initial features, \textit{diagram of the attention heads I guess} etc.


\section{Requirements analysis}

Tasks to be implemented (according to proposal: work to be done, success criteria, possible extensions), their relative importance (priority) and difficulty. Provide the order in which the tasks should be carried out to show good planning skills and account for the changes in proposal where the preprocessing pipeline turned out to be more important than the neural network implementation.

\section{Software engineering practice}
Implementing a flexible preprocessing pipeline which could be customised in the future for a variety of machine learning tasks even outside graph neural networks (a package).

Modular structure encapsulating specific task and having well defined documentations of the others.

Description of software engineering techniques: planning out and executing the project based on requirements analysis, setting tasks, and smoothly meeting the success criteria.

Code reuse (of open source well tested libraries), follow documentation and follow the PEP-8 style guide (or whatever PyCharm encourages).

Incremental development.

Modular structure: e.g. data processing, graph construction, graph neural network modules, robustness evaluation framework. Figure out where validation and cross validation sections should be (while training, separately etc.)

Diagram of the pipelines and module interaction (like in google design docs)


\section{Choice of tools}
PyTorch, PyTorch geometric extension, graph spectral filters/convolutions, message passing, time-series preprocessing into correlation matrices, IDEs, backup strategies

\section{Starting point}
\begin{itemize}
    \item dataset, preprocessed by Dr Richard A.I. Bethlehem
    \item PyTorch, PyTorch geometric implementing GCN and GAT APIs and the graph API
    \item no previous experience with graph neural networks or the mathematics behind it
    \item no previous experience with PyTorch; limited experience with machine learning frameworks (basics of TensorFlow), no experience with neuroimaging data
\end{itemize}
