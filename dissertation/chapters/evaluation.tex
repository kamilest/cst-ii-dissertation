\chapter{Evaluation}
% This is where Assessors will be looking for signs of success and for evidence of thorough and systematic evaluation as discussed in Section 8.3. Sample output, tables of timings and photographs of workstation screens, oscilloscope traces or circuit boards may be included. A graph that does not indicate confidence intervals will generally leave a professional scientist with a negative impression.
% As with code, voluminous examples of sample output are usually best left to appendices or omitted altogether.
% There are some obvious questions which this chapter will address. How many of the original goals were achieved? Were they proved to have been achieved? Did the program, hardware, or theory really work?
% Assessors are well aware that large programs will very likely include some residual bugs. It should always be possible to demonstrate that a program works in simple cases and it is instructive to demonstrate how close it is to working in a really ambitious case.

% ~2,000 words

\begin{itemize}
    \item What were the best hyperparameters?
    \item Plot with test set performance of best GCN and best GAT model
    \item Discussion comparing GCN and GAT performance â€“ compare with literature on brain age estimation? (i.e. this model is quite poor)
    \item Give possible reasons why (why??)
    \item Statistical significance of the results compared to the baseline (e.g. Pearson's $r$ method in Python seems to return some $p$-value with it..?)
    \item Robustness of the graphs
\end{itemize}


% \section{Comparison against existing benchmarks}

% Compare to the Kaufmann et al.'s \textit{xgboost} approach \cite{kaufmann2019} ($r \sim 0.93$); and the other package that was cited in the same paper.

% Possibly compare to other non-graph (relatively baseline) (neural network) architectures, e.g. ElasticNet, MLP,...

